{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Librer√≠as"
      ],
      "metadata": {
        "id": "8JwOmkFWWl2c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U8lSWt4tv7iN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Model, Sequential \n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, BatchNormalization, Conv2DTranspose, UpSampling2D, Flatten, Activation, Reshape\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adadelta \n",
        "from google.colab import drive\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "XaWleMoUX43-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acceder a los datos de Google Drive"
      ],
      "metadata": {
        "id": "2L9U-r9DX87p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uKqrPDRnMX_",
        "outputId": "553eadb9-7e95-4baf-c214-26b351884631"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar datos y establecer (n_muestras, 224, 224, 1) como \"shape\"."
      ],
      "metadata": {
        "id": "XkSp6GISYDSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = \"/content/drive/MyDrive/mamma.npy\"\n",
        "np_images = np.load(images, allow_pickle=True)\n",
        "normalized_images = np_images/255\n",
        "normalized_images = np.reshape(normalized_images,(normalized_images.shape[0],224,224,1))"
      ],
      "metadata": {
        "id": "6ByDelgAYGxW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generador"
      ],
      "metadata": {
        "id": "o0fiSboFYPDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_architecture(depth=64, p=0.4):\n",
        "    noise_shape = Input((32,))\n",
        "\n",
        "    dense1 = Dense(7*7*depth)(noise_shape)\n",
        "    dense1 = BatchNormalization(momentum=0.9)(dense1) \n",
        "    dense1 = Activation(activation='relu')(dense1)\n",
        "    dense1 = Reshape((7,7,depth))(dense1)\n",
        "    dense1 = Dropout(p)(dense1)\n",
        "    \n",
        "    conv1 = UpSampling2D()(dense1)\n",
        "    conv1 = Conv2DTranspose(int(depth/2), \n",
        "                            kernel_size=5, padding='same', \n",
        "                            activation=None,)(conv1)\n",
        "    conv1 = BatchNormalization(momentum=0.9)(conv1)\n",
        "    conv1 = Activation(activation='relu')(conv1)\n",
        "    \n",
        "    conv2 = UpSampling2D()(conv1)\n",
        "    conv2 = Conv2DTranspose(int(depth/4), \n",
        "                            kernel_size=5, padding='same', \n",
        "                            activation=None,)(conv2)\n",
        "    conv2 = BatchNormalization(momentum=0.9)(conv2)\n",
        "    conv2 = Activation(activation='relu')(conv2)\n",
        "    \n",
        "    conv3 = UpSampling2D()(conv2)\n",
        "    conv3 = Conv2DTranspose(int(depth/8), \n",
        "                            kernel_size=5, padding='same', \n",
        "                            activation=None,)(conv3)\n",
        "    conv3 = BatchNormalization(momentum=0.9)(conv3)\n",
        "    conv3 = Activation(activation='relu')(conv3)\n",
        "    \n",
        "    conv4 = UpSampling2D()(conv3)\n",
        "    conv4 = Conv2DTranspose(int(depth/16), \n",
        "                            kernel_size=5, padding='same', \n",
        "                            activation=None,)(conv4)\n",
        "    conv4 = BatchNormalization(momentum=0.9)(conv4)\n",
        "    conv4 = Activation(activation='relu')(conv4)\n",
        "    \n",
        "    conv5 = UpSampling2D()(conv4)\n",
        "    conv5 = Conv2DTranspose(int(depth/16), \n",
        "                            kernel_size=5, padding='same', \n",
        "                            activation=None,)(conv5)\n",
        "    conv5 = BatchNormalization(momentum=0.9)(conv5)\n",
        "    conv5 = Activation(activation='relu')(conv5)\n",
        "\n",
        "    image = Conv2DTranspose(1, kernel_size=5, padding='same', \n",
        "                   activation='tanh')(conv5)\n",
        " \n",
        "    model = Model(inputs=noise_shape, outputs=image)\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "tr_SQzBiYQz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = generator_architecture()\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "k68LxapqYmY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_architecture(depth=64, p=0.4):\n",
        "\n",
        "    image = Input((224,224,1))\n",
        "\n",
        "    conv1 = Conv2D(depth*1, 5, strides=2, \n",
        "                   padding='same', activation='relu')(image)\n",
        "    conv1 = BatchNormalization(momentum=0.9)(conv1)\n",
        "    conv1 = LeakyReLU(alpha=0.2)(conv1)\n",
        "    conv1 = Dropout(p)(conv1)\n",
        "    \n",
        "    conv2 = Conv2D(depth*2, 5, strides=2, \n",
        "                   padding='same', activation='relu')(conv1)\n",
        "    conv2 = LeakyReLU(alpha=0.2)(conv2)             \n",
        "    conv2 = BatchNormalization(momentum=0.9)(conv2)               \n",
        "    conv2 = Dropout(p)(conv2)\n",
        "    \n",
        "    conv3 = Conv2D(depth*4, 5, strides=2, \n",
        "                   padding='same', activation='relu')(conv2)\n",
        "    conv3 = LeakyReLU(alpha=0.2)(conv3)\n",
        "    conv3 = BatchNormalization(momentum=0.9)(conv3)  \n",
        "    conv3 = Dropout(p)(conv3)\n",
        "    \n",
        "    conv4 = Conv2D(depth*8, 5, strides=2, \n",
        "                   padding='same', activation='relu')(conv3)\n",
        "    conv4 = LeakyReLU(alpha=0.2)(conv4)               \n",
        "    conv4 = BatchNormalization(momentum=0.9)(conv4)                 \n",
        "    conv4 = Flatten()(Dropout(p)(conv4))\n",
        "\n",
        "    prediction = Dense(1, activation='sigmoid')(conv4)\n",
        "\n",
        "    model = Model(inputs=image, outputs=prediction)\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "121Fr2rNwPEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = discriminator_architecture()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZjnvUm1wXSr",
        "outputId": "7e2824c1-cbbd-412d-ba53-50454648333d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 224, 224, 1)]     0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 112, 112, 64)      1664      \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 112, 112, 64)     256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 56, 56, 128)       204928    \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 56, 56, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 28, 28, 256)       819456    \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " batch_normalization_34 (Bat  (None, 28, 28, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 14, 14, 512)       3277312   \n",
            "                                                                 \n",
            " leaky_re_lu_11 (LeakyReLU)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 14, 14, 512)      2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 100352)            0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 100353    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,407,553\n",
            "Trainable params: 4,405,633\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.0004, decay=6e-8, clipvalue=1.0), metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCNpgjtjwYid",
        "outputId": "1e9ae78b-9c04-426f-9996-32bfbb9a07ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = Input(shape=(32,))\n",
        "synthetic_img = generator(noise)"
      ],
      "metadata": {
        "id": "K9hp5_upwd9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.trainable = False"
      ],
      "metadata": {
        "id": "Iuz-d45NwfWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator_pred = discriminator(synthetic_img)\n",
        "adversarial_model = Model(noise, discriminator_pred)"
      ],
      "metadata": {
        "id": "zyCuaEU8ZMGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.0004, decay=3e-8, clipvalue=1.0), metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYNDW10mwheS",
        "outputId": "4af2c228-a039-48a8-d3dc-4935b25986ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar modelo e im√°genes creadas por cada \"x\" epochs que se establezcan."
      ],
      "metadata": {
        "id": "EWAjDTOGZu48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GENERATOR_PATH = \"/content/drive/MyDrive/generator_model_DCGAN/\"\n",
        "IMAGES = \"/content/drive/MyDrive/images/\""
      ],
      "metadata": {
        "id": "fgLvGAR31zNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_procedure(epochs=4000, batch=32):\n",
        "    \n",
        "    discriminator_stats, adversarial_stats = [], []\n",
        "    discriminator_loss , discriminator_acc = 0, 0\n",
        "    adversarial_loss, adversarial_acc = 0, 0\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        real_imgs = np.reshape(normalized_images[np.random.choice(normalized_images.shape[0],batch,replace=False)],(batch,224,224,1))\n",
        "        fake_imgs = generator.predict(np.random.uniform(-1.0, 1.0, size=[batch, 32]))\n",
        "    \n",
        "        real_and_fake_imgs = np.concatenate((real_imgs,fake_imgs))\n",
        "        \n",
        "        discriminator_labels = np.ones([2*batch,1])\n",
        "        discriminator_labels[batch:,:] = 0\n",
        "        \n",
        "        discriminator_stats.append(discriminator.train_on_batch(real_and_fake_imgs,discriminator_labels))\n",
        "        discriminator_loss += discriminator_stats[-1][0]\n",
        "        discriminator_acc += discriminator_stats[-1][1]\n",
        "        \n",
        "        noise = np.random.uniform(-1.0, 1.0, size=[batch, 32])\n",
        "        y = np.ones([batch,1])\n",
        "\n",
        "        adversarial_stats.append(adversarial_model.train_on_batch(noise,y)) \n",
        "        adversarial_loss += adversarial_stats[-1][0]\n",
        "        adversarial_acc += adversarial_stats[-1][1]\n",
        "             \n",
        "        print(\"%d: [D loss: %f, acc: %f]\" % (epoch, discriminator_loss/epoch, discriminator_acc/epoch))\n",
        "\n",
        "        if (epoch+1)%100 == 0: \n",
        "\n",
        "          noise = np.random.uniform(-1.0, 1.0, size=[16, 32])\n",
        "          gen_imgs = generator.predict(noise)\n",
        "          plt.figure(figsize=(7,7))\n",
        "\n",
        "          for k in range(gen_imgs.shape[0]):\n",
        "            plt.subplot(4, 4, k+1)\n",
        "            plt.imshow(gen_imgs[k, :, :, 0], cmap='gray')\n",
        "            plt.axis('off')\n",
        "            plt.savefig(IMAGES+'epoch%d.png' % (epoch))\n",
        " \n",
        "          plt.tight_layout()\n",
        "          plt.show()\n",
        "\n",
        "    generator.save(GENERATOR_PATH+'gan_generator_%d.h5' % (epoch))\n",
        "    \n",
        "    return discriminator_stats"
      ],
      "metadata": {
        "id": "d33uPgZbwimg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator_metrics, adversarial_metrics = training_procedure()"
      ],
      "metadata": {
        "id": "0uqvr9MMwldU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}