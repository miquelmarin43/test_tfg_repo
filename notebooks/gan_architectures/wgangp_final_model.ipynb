{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia_de_WGAN_DISCO_DURO_BATCH_SIZE_8_GP_01.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Librerías"
      ],
      "metadata": {
        "id": "exI92BPGo-Ho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4njhCp0CkiCg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, Dropout, BatchNormalization, Conv2DTranspose, UpSampling2D, Flatten, Activation, Reshape \n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "tZJC-qEMm1zy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acceder a los datos de Google Drive"
      ],
      "metadata": {
        "id": "WrHs4wgipEEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iDwGSp54pDkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar datos"
      ],
      "metadata": {
        "id": "XawGJgtBpHjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_images = \"/content/drive/MyDrive/mamma_disco_duro.npy\"\n",
        "data = np.load(input_images, allow_pickle=True)"
      ],
      "metadata": {
        "id": "Ek52AjwTlDRY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GENERATOR_PATH = \"/content/drive/MyDrive/mammi_disco_duro_WGAN_BATCH_SIZE_8_GP_10_models/\""
      ],
      "metadata": {
        "id": "w37O0FS1dVQ7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clase WGAN: contiene inicialización de parámetros y entrenamiento de la red"
      ],
      "metadata": {
        "id": "wMfE_L4TpKQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WGAN_GP:\n",
        "    def __init__(self, img_shape, sample_shape=(4,4), latent=128):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        INICIALIZACIÓN PARÁMETROS Y ARQUITECTURAS GENERADOR Y DISCRIMINADOR\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.img_shape = img_shape\n",
        "        self.sample_shape = sample_shape\n",
        "        self.latent_dim = latent\n",
        "        self.n_critic = 5\n",
        "\n",
        "        self.generator_model = Generator(self.img_shape, self.latent_dim).architecture()\n",
        "        self.discriminator_model = Discriminator(self.img_shape, self.latent_dim).architecture()\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        PARA EL PROCESO DE TRANSFER LEARNING. CARGAR PESOS DEL MEJOR MODELO CON IMÁGENES USF\n",
        "\n",
        "        self.generator_model.load_weights(GENERATOR_PATH+'generator_weights.h5')\n",
        "        self.discriminator_model.load_weights(DISCRIMINATOR_PATH+'discriminator_weights.h5')\n",
        "        \"\"\"\n",
        "\n",
        "        discriminator = Discriminator(self.img_shape, self.latent_dim, self.generator_model, self.discriminator_model)\n",
        "        self.discriminator_train_func = discriminator.build()\n",
        "\n",
        "        combined = Generator(self.img_shape, self.latent_dim, self.generator_model, self.discriminator_model)\n",
        "        self.generator = combined.generator\n",
        "        self.combined_train_func = combined.build()\n",
        "\n",
        "    \n",
        "\n",
        "    def train_one_epoch(self, X_train, epoch, batch_size, valid, fake, dummy):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        PROCESO ENTRENAMIENTO PARA UNA EPOCH\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        for _ in range(self.n_critic):\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            imgs = X_train[idx]\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            alpha = np.random.uniform(size=(batch_size, 1, 1 ,1))\n",
        "            d_loss_real, d_loss_fake = self.discriminator_train_func([imgs, noise, alpha])\n",
        "            d_loss = d_loss_real - d_loss_fake\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "        g_loss, = self.combined_train_func([noise])\n",
        "\n",
        "        print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss, g_loss))\n",
        "\n",
        "    def general_training(self, data, epochs, batch_size=128, sample_interval=200):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        PROCESO ENTRENAMIENTO GENERAL\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        X_train = data\n",
        "\n",
        "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "        X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "        valid =-np.ones((batch_size, 1))\n",
        "        fake = np.ones((batch_size, 1))\n",
        "        dummy = np.zeros((batch_size, 1))\n",
        "\n",
        "        for epoch in range(1, epochs+1):\n",
        "            self.train_one_epoch(X_train, epoch, batch_size, valid, fake, dummy)\n",
        "\n",
        "            if epoch % sample_interval == 0:\n",
        "                self.sample_images(epoch)\n",
        "                #print(GENERATOR_PATH+'wgangp_generator_%d.h5' % (epoch))\n",
        "                self.generator.save(GENERATOR_PATH+'wgangp_generator_%d.h5' % (epoch))\n",
        "\n",
        "    def sample_images(self, epoch):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        OBTENCIÓN IMÁGENES SINTÉTICAS\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        r, c = self.sample_shape\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        samples = \"/content/drive/MyDrive/mammi_disco_duro_WGAN_BATCH_SIZE_8_GP_10_images/\"\n",
        "        if not os.path.exists(samples):\n",
        "            os.mkdir(samples)\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"%s%d.png\" % (samples, epoch))\n",
        "        plt.close()\n"
      ],
      "metadata": {
        "id": "TRbG9p9bklSR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clase Generador"
      ],
      "metadata": {
        "id": "Fx6mTLXrpWKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator:\n",
        "    def __init__(self, img_shape=None, latent=None, generator_model=None, discriminator_model=None):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        INICIALIZACIÓN PARÁMETROS\n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "        self.img_shape = img_shape\n",
        "        self.latent_dim = latent\n",
        "\n",
        "        self.generator = generator_model\n",
        "        self.discriminator = discriminator_model\n",
        "\n",
        "    \n",
        "    def build(self):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        FASE ENTRENAMIENTO GENERADOR\n",
        "\n",
        "        \"\"\"\n",
        "        self.discriminator.trainable = False\n",
        "        self.generator.trainable = True\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        z = self.generator(noise)\n",
        "        loss = -K.mean(self.discriminator(z))\n",
        "        \n",
        "        training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(params=self.generator.trainable_weights, loss=loss)\n",
        "        train_func = K.function([noise], [loss], training_updates)\n",
        "\n",
        "        return train_func\n",
        "\n",
        "    def architecture(self):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        ARQUITECTURA GENERADOR\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(64 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
        "        model.add(Reshape((7, 7, 64)))\n",
        "\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2DTranspose(64/2, kernel_size=4, padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2DTranspose(64/4, kernel_size=4, padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2DTranspose(64/8, kernel_size=4, padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2DTranspose(64/16, kernel_size=4, padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2DTranspose(64/16, kernel_size=4, padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "\n",
        "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Conv2D(self.img_shape[2], kernel_size=4, padding=\"same\"))\n",
        "        model.add(Activation(\"tanh\"))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(inputs=noise, outputs=img)"
      ],
      "metadata": {
        "id": "gljAkQpekpNF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clase Discriminador"
      ],
      "metadata": {
        "id": "VhuAfxr4pZRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator:\n",
        "    def __init__(self, img_shape=None, latent=None, generator_model=None, discriminator_model=None):\n",
        "\n",
        "        \"\"\"\n",
        "      \n",
        "        INICIALIZACIÓN PARÁMETROS\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.img_shape = img_shape\n",
        "        self.latent_dim = latent\n",
        "\n",
        "        self.generator = generator_model\n",
        "        self.discriminator = discriminator_model\n",
        "\n",
        "    def get_interpolated(self, real_img, fake_img):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        OBTENCIÓN DE LA MUESTRA INTERPOLADA MEDIANTE MUESTRAS REALES Y FALSAS\n",
        "\n",
        "        \"\"\"\n",
        "        alpha = K.placeholder(shape=(None,1,1,1))\n",
        "        interpolated_img = Input(shape=self.img_shape, \n",
        "                                tensor=alpha*real_img + (1-alpha)*fake_img)\n",
        "\n",
        "        return interpolated_img, alpha\n",
        "\n",
        "    def gradient_penalty_loss(self, real_img, fake_img, interpolated_img):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        CÁLCULO FUNCIÓN DE PÉRDIDA A PARTIR DE DICHA MUESTRA INTERPOLADA \n",
        "        PREVIAMENTE CALCULADA\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        loss_real = K.mean(self.discriminator(real_img))\n",
        "        loss_fake = K.mean(self.discriminator(fake_img))\n",
        "\n",
        "        grad_mixed = K.gradients(self.discriminator(interpolated_img), [interpolated_img])[0]\n",
        "        gradients_sqr = K.square(grad_mixed)\n",
        "        norm_grad_mixed = K.sqrt(K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape))))\n",
        "        grad_penalty = K.mean(K.square(norm_grad_mixed-1))\n",
        "\n",
        "        loss = loss_fake - loss_real + 10 * grad_penalty\n",
        "\n",
        "        return loss_real, loss_fake, loss\n",
        "\n",
        "    def build(self):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        FASE ENTRENAMIENTO DISCRIMINADOR\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.generator.trainable = False\n",
        "        self.discriminator.trainable = True\n",
        "\n",
        "        real_img = Input(shape=self.img_shape)\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        fake_img = self.generator(noise)\n",
        "\n",
        "        interpolated_img,alpha = self.get_interpolated(real_img, fake_img)\n",
        "\n",
        "        loss_real, loss_fake, loss = self.gradient_penalty_loss(real_img, fake_img, interpolated_img)\n",
        "\n",
        "        training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(params=self.discriminator.trainable_weights, loss=loss)\n",
        "        discriminator_train = K.function([real_img, noise, alpha],\n",
        "                                [loss_real, loss_fake],    \n",
        "                                training_updates)\n",
        "\n",
        "        return discriminator_train\n",
        "\n",
        "    def architecture(self):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        ARQUITECTURA DEL DISCRIMINADOR\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(64, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(64*2, kernel_size=3, strides=2, padding=\"same\"))\n",
        "\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(64*4, kernel_size=3, strides=2, padding=\"same\"))\n",
        "\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(64*8, kernel_size=3, strides=1, padding=\"same\"))\n",
        "\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(inputs=img, outputs=validity)\n"
      ],
      "metadata": {
        "id": "sA0mM1jUkq5P"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    wgan_gp = WGAN_GP(img_shape=(224,224,1))\n",
        "    wgan_gp.general_training(data=data, epochs=4000, batch_size=8, sample_interval=100)"
      ],
      "metadata": {
        "id": "RlvAoqakmObF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}